{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class SequentialRecommendationDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        self.max_seq_length = 0\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' ')\n",
    "                user_id = int(parts[0])\n",
    "                sequence = list(map(int, parts[1:]))\n",
    "                self.data.append((user_id, sequence))\n",
    "                self.max_seq_length = max(self.max_seq_length, len(sequence))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id, sequence = self.data[idx]\n",
    "        input_seq = torch.tensor(sequence[:-1], dtype=torch.long)\n",
    "        target_seq = torch.tensor(sequence[1:], dtype=torch.long)\n",
    "        return user_id, input_seq, target_seq\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    user_ids, input_seqs, target_seqs = zip(*batch)\n",
    "    input_seqs = nn.utils.rnn.pad_sequence(input_seqs, batch_first=True, padding_value=0)\n",
    "    target_seqs = nn.utils.rnn.pad_sequence(target_seqs, batch_first=True, padding_value=0)\n",
    "    return user_ids, input_seqs, target_seqs\n",
    "    \n",
    "dataset = SequentialRecommendationDataset('sequential_recommendation_data.txt')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6007, 785, 1791, 5785, 5028, 107, 93, 5809, 3200, 5555, 5016, 1206, 5156, 2624, 773, 1099, 2669, 4297, 4603, 3865, 3293, 1126, 4001, 3233, 1256, 2486, 6019, 416, 3561, 115, 2902, 1154)\n",
      "32\n",
      "tensor([[ 110, 3101, 2021,  ...,    0,    0,    0],\n",
      "        [1193, 1917,  593,  ...,    0,    0,    0],\n",
      "        [1466, 1610, 2531,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [2011, 2028, 1407,  ...,    0,    0,    0],\n",
      "        [1221, 3260, 3654,  ...,    0,    0,    0],\n",
      "        [1682, 3660,  640,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "# print the first batch\n",
    "for user_ids, input_seqs, target_seqs in dataloader:\n",
    "    print(user_ids)\n",
    "    print(len(input_seqs))\n",
    "    print(target_seqs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3953\n",
      "Epoch 1, Loss: 1.699788212776184\n",
      "Epoch 2, Loss: 1.5240942239761353\n",
      "Epoch 3, Loss: 0.8340753316879272\n",
      "Epoch 4, Loss: 0.8427436351776123\n",
      "Epoch 5, Loss: 1.597973346710205\n"
     ]
    }
   ],
   "source": [
    "# define the rnn model\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "# Hyperparameters\n",
    "# input size should be the number of items in the dataset + 1 (for padding) , so calculate it from the .txt file\n",
    "input_size = 0\n",
    "with open('sequential_recommendation_data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split(' ')\n",
    "        sequence = list(map(int, parts[1:]))\n",
    "        input_size = max(input_size, max(sequence))\n",
    "input_size += 1\n",
    "\n",
    "print(input_size)\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = input_size\n",
    "num_epochs = 5\n",
    "learning_rate = 0.03\n",
    "\n",
    "# Initialize the model, loss function, and optimizer and train the model on gpu\n",
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNNModel(input_size, hidden_size, num_layers, num_classes)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (user_ids, input_seqs, target_seqs) in enumerate(dataloader):\n",
    "        \n",
    "        model.train()\n",
    "        input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)\n",
    "        outputs = model(input_seqs)\n",
    "        # print(outputs.shape, target_seqs.shape)\n",
    "        loss = criterion(outputs.view(-1, num_classes), target_seqs.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if (i+1) % 10 == 0:\n",
    "        #     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        #            .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'rnnmodel.ckpt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "In this section, we will perform inference on our trained model. The goal is to predict the next sequence of items based on a given input item. This is a common scenario in recommendation systems where we want to predict what items a user might interact with next, based on their past interactions.\n",
    "\n",
    "The process will work as follows:\n",
    "\n",
    "1. We start by feeding the model an input item.\n",
    "2. The model will generate a prediction for the next item.\n",
    "3. We then take the model's prediction and use it as the new input, repeating the process.\n",
    "4. This is done iteratively, up to 5 times, to generate a sequence of recommended items.\n",
    "\n",
    "This method of using the model's own predictions as input for subsequent predictions is known as autoregression.\n",
    "\n",
    "Let's see how this works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting item: 452\n",
      "Generated sequence: [452, 1210, 1270, 750, 924, 3471]\n"
     ]
    }
   ],
   "source": [
    "# Now lets do inference where i will give the model one item and it will predict the next sequence upto 5 items(feed the output of the model as input to the model again)\n",
    "\n",
    "# Load the model checkpoint\n",
    "model = RNNModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model.load_state_dict(torch.load('rnnmodel.ckpt'))\n",
    "model.eval()\n",
    "\n",
    "# Inference\n",
    "\n",
    "# Choose a random item from the dataset\n",
    "import random\n",
    "item = random.randint(1, input_size-1)\n",
    "print('Starting item:', item)\n",
    "\n",
    "# Initialize the input sequence with the chosen item\n",
    "input_seq = torch.tensor([[item]]).to(device)\n",
    "\n",
    "# Generate the next 5 items in the sequence\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        output = model(input_seq)\n",
    "        _, predicted = torch.max(output[:, -1, :], 1)\n",
    "        input_seq = torch.cat((input_seq, predicted.unsqueeze(1)), dim=1)\n",
    "        \n",
    "print('Generated sequence:', input_seq.squeeze().tolist())\n",
    "\n",
    "torch.save(model.state_dict(), 'rnnmodel.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now create the transformer decoder architecture and train it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.245722770690918\n",
      "Epoch 2, Loss: 2.180192232131958\n",
      "Epoch 3, Loss: 1.989233136177063\n",
      "Epoch 4, Loss: 2.133683681488037\n",
      "Epoch 5, Loss: 1.973725438117981\n"
     ]
    }
   ],
   "source": [
    "# create the transformer deocder model which takes the inout sequence one by one and predicts the next item in the sequence and train the model on gpu use teacher forcing technique\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, num_items, embed_size, num_layers, num_heads, hidden_dim):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items, embed_size)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(embed_size, num_heads, hidden_dim),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, num_items)\n",
    "        \n",
    "    def forward(self, input_seqs):\n",
    "        embeddings = self.item_embedding(input_seqs)\n",
    "        output = self.transformer_decoder(embeddings, embeddings)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "# Hyperparameters\n",
    "num_items = 0\n",
    "with open('sequential_recommendation_data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split(' ')\n",
    "        sequence = list(map(int, parts[1:]))\n",
    "        num_items = max(num_items, max(sequence))\n",
    "        \n",
    "num_items += 1\n",
    "embed_size = 128\n",
    "num_layers = 1\n",
    "num_heads = 2\n",
    "hidden_dim = 256\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model, loss function, and optimizer and train the model on gpu\n",
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerDecoder(num_items, embed_size, num_layers, num_heads, hidden_dim)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(dataloader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (user_ids, input_seqs, target_seqs) in enumerate(dataloader):\n",
    "        \n",
    "        model.train()\n",
    "        input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)\n",
    "        outputs = model(input_seqs)\n",
    "        loss = criterion(outputs.view(-1, num_items), target_seqs.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'transformermodel.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting item: 717\n",
      "Generated sequence: [717, 2858, 2706, 2997, 3285, 3298, 2694, 2710, 2770, 2433, 223]\n"
     ]
    }
   ],
   "source": [
    "# Now lets do inference where i will give the model one item and it will predict the next sequence upto 5 items(feed the output of the model as input to the model again)\n",
    "\n",
    "# Load the model checkpoint\n",
    "model = TransformerDecoder(num_items, embed_size, num_layers, num_heads, hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load('transformermodel.ckpt'))\n",
    "model.eval()\n",
    "\n",
    "# Inference\n",
    "\n",
    "# Choose a random item from the dataset\n",
    "import random\n",
    "item = random.randint(1, num_items-1)\n",
    "print('Starting item:', item)\n",
    "\n",
    "# Initialize the input sequence with the chosen item\n",
    "input_seq = torch.tensor([[item]]).to(device)\n",
    "\n",
    "# Generate the next 5 items in the sequence\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        output = model(input_seq)\n",
    "        _, predicted = torch.max(output[:, -1, :], 1)\n",
    "        input_seq = torch.cat((input_seq, predicted.unsqueeze(1)), dim=1)\n",
    "        \n",
    "print('Generated sequence:', input_seq.squeeze().tolist())\n",
    "\n",
    "#save the model checkpoint\n",
    "torch.save(model.state_dict(), 'transformermodel.ckpt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Model - NDCG@5: 1.0000, NDCG@10: 1.0000\n",
      "Transformer Model - NDCG@5: 1.0000, NDCG@10: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Load both the models and compare the results of ndcg@5 and ndcg@10 for both the models by calculating dcg and idcg and then calculating ndcg\n",
    "\n",
    "#load rnn and transformer model\n",
    "\n",
    "transformer_model = TransformerDecoder(num_items, embed_size, num_layers, num_heads, hidden_dim).to(device)\n",
    "transformer_model.load_state_dict(torch.load('transformermodel.ckpt'))\n",
    "transformer_model.eval()\n",
    "\n",
    "rnn_model = RNNModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "rnn_model.load_state_dict(torch.load('rnnmodel.ckpt'))\n",
    "rnn_model.eval()\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = SequentialRecommendationDataset('sequential_recommendation_data.txt')\n",
    "\n",
    "#calculate the dcg and idcg for both the models\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n",
    "\n",
    "# Calculate the NDCG@5 and NDCG@10 for both models\n",
    "import numpy as np\n",
    "\n",
    "ndcg5_rnn = 0\n",
    "ndcg10_rnn = 0\n",
    "ndcg5_transformer = 0\n",
    "ndcg10_transformer = 0\n",
    "\n",
    "for user_id, input_seq, target_seq in dataloader:\n",
    "    input_seq = input_seq.to(device)\n",
    "    target_seq = target_seq.to(device)\n",
    "    \n",
    "    # RNN model\n",
    "    rnn_output = rnn_model(input_seq)\n",
    "    rnn_output = rnn_output[:, -1, :]\n",
    "    _, rnn_predicted = torch.topk(rnn_output, k=num_items)\n",
    "    rnn_predicted = rnn_predicted.cpu().numpy()\n",
    "    rnn_target = target_seq[:, -1].cpu().numpy()\n",
    "    rnn_ndcg5 = ndcg_at_k([int(item in rnn_predicted[i]) for i, item in enumerate(rnn_target)], 5)\n",
    "    rnn_ndcg10 = ndcg_at_k([int(item in rnn_predicted[i]) for i, item in enumerate(rnn_target)], 10)\n",
    "    ndcg5_rnn += rnn_ndcg5\n",
    "    ndcg10_rnn += rnn_ndcg10\n",
    "    \n",
    "    # Transformer model\n",
    "    transformer_output = transformer_model(input_seq)\n",
    "    transformer_output = transformer_output[:, -1, :]\n",
    "    _, transformer_predicted = torch.topk(transformer_output, k=num_items)\n",
    "    transformer_predicted = transformer_predicted.cpu().numpy()\n",
    "    transformer_target = target_seq[:, -1].cpu().numpy()\n",
    "    transformer_ndcg5 = ndcg_at_k([int(item in transformer_predicted[i]) for i, item in enumerate(transformer_target)], 5)\n",
    "    transformer_ndcg10 = ndcg_at_k([int(item in transformer_predicted[i]) for i, item in enumerate(transformer_target)], 10)\n",
    "    ndcg5_transformer += transformer_ndcg5\n",
    "    ndcg10_transformer += transformer_ndcg10\n",
    "    \n",
    "ndcg5_rnn /= len(dataloader)\n",
    "ndcg10_rnn /= len(dataloader)\n",
    "ndcg5_transformer /= len(dataloader)\n",
    "ndcg10_transformer /= len(dataloader)\n",
    "\n",
    "print(f'RNN Model - NDCG@5: {ndcg5_rnn:.4f}, NDCG@10: {ndcg10_rnn:.4f}')\n",
    "\n",
    "print(f'Transformer Model - NDCG@5: {ndcg5_transformer:.4f}, NDCG@10: {ndcg10_transformer:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
